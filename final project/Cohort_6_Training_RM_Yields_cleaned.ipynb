{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importin Libraries\n",
    "\n",
    "import pandas as pd # Data manipulation\n",
    "import numpy as np # Matrix calculation\n",
    "import geopandas as gpd # GIS of Pandas\n",
    "import seaborn as sb # Parof of matplotlib for Data Viz\n",
    "import matplotlib.pyplot as plt # data viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading 2000-2023 Aggregated Yield Data\n",
    "df_agg_00_23=pd.read_csv('/users/ruhidmirzayev/palette/notebooks/cohort 6/rm_yield_00_23_major_crops.csv')\n",
    "\n",
    "# Reading GIS\n",
    "gdf_rm=gpd.read_file('/users/ruhidmirzayev/palette/notebooks/cohort 6/SK_RM_Shapefiles/RuralMunicipality.shp')\n",
    "\n",
    "# Changing data type \n",
    "gdf_rm['RMNO']=gdf_rm['RMNO'].astype(int)\n",
    "gdf_rm_clean=gdf_rm[['RMNO', 'geometry']].rename(columns={'RMNO': 'RM'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal Clusters recommeded by the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Assuming df_agg_00_23 is already loaded\n",
    "crops = ['Canola', 'Spring Wheat', 'Durum', 'Oats', 'Lentils', 'Peas', 'Barley']\n",
    "\n",
    "# Function to prepare data for each crop\n",
    "def prepare_data_for_crop(df, crop):\n",
    "    columns = [f'{crop}_mean', f'{crop}_std']\n",
    "    crop_data = df[columns].dropna().values\n",
    "    return crop_data\n",
    "\n",
    "# Standardize the data\n",
    "def standardize_data(data):\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(data)\n",
    "    return data_scaled\n",
    "\n",
    "# Function to perform spectral clustering and choose the optimal number of clusters\n",
    "def spectral_clustering(data, n_clusters):\n",
    "    clustering = SpectralClustering(n_clusters=n_clusters, assign_labels=\"discretize\", random_state=0)\n",
    "    labels = clustering.fit_predict(data)\n",
    "    return labels\n",
    "\n",
    "# Function to find the optimal number of clusters\n",
    "def find_optimal_clusters(data, max_k):\n",
    "    scores = []\n",
    "    for k in range(2, max_k+1):\n",
    "        labels = spectral_clustering(data, k)\n",
    "        score = silhouette_score(data, labels)\n",
    "        scores.append(score)\n",
    "    optimal_k = scores.index(max(scores)) + 2\n",
    "    return optimal_k, scores\n",
    "\n",
    "# Iterate over each crop and perform clustering\n",
    "for crop in crops:\n",
    "    # Prepare the data for the crop\n",
    "    crop_data = prepare_data_for_crop(df_agg_00_23, crop)\n",
    "    \n",
    "    # Standardize the data\n",
    "    crop_data_scaled = standardize_data(crop_data)\n",
    "    \n",
    "    # Find the optimal number of clusters\n",
    "    optimal_k, scores = find_optimal_clusters(crop_data_scaled, 10)\n",
    "    \n",
    "    # Perform spectral clustering with the optimal number of clusters\n",
    "    labels = spectral_clustering(crop_data_scaled, optimal_k)\n",
    "    \n",
    "    # Add the cluster labels to the original dataframe\n",
    "    df_agg_00_23[f'{crop}_Spectral_Cluster_Optimal'] = np.nan\n",
    "    df_agg_00_23.loc[~df_agg_00_23[[f'{crop}_mean', f'{crop}_std']].isna().any(axis=1), f'{crop}_Spectral_Cluster_Optimal'] = labels\n",
    "    \n",
    "    # Print the results\n",
    "    print(f'Optimal number of clusters for {crop}: {optimal_k}')\n",
    "    print(f'Silhouette scores for {crop}: {scores}')\n",
    "    \n",
    "    # Visualize the silhouette scores\n",
    "    plt.plot(range(2, 11), scores, marker='o')\n",
    "    plt.title(f'Silhouette Scores for {crop}')\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('Silhouette Score')\n",
    "    plt.show()\n",
    "    \n",
    "    # Visualize the clustering results\n",
    "    plt.scatter(df_agg_00_23[f'{crop}_mean'], df_agg_00_23[f'{crop}_std'], c=df_agg_00_23[f'{crop}_Spectral_Cluster_Optimal'], cmap='viridis')\n",
    "    plt.title(f'Spectral Clustering Results for {crop}')\n",
    "    plt.xlabel(f'{crop}_mean')\n",
    "    plt.ylabel(f'{crop}_std')\n",
    "    plt.colorbar(label='Cluster')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customized Clusters by Expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "# Assuming df_agg_00_23 is already loaded\n",
    "crops = ['Canola', 'Spring Wheat', 'Durum', 'Oats', 'Lentils', 'Peas', 'Barley']\n",
    "\n",
    "# Function to prepare data for each crop\n",
    "def prepare_data_for_crop(df, crop):\n",
    "    columns = [f'{crop}_mean', f'{crop}_std']\n",
    "    crop_data = df[columns].dropna().values\n",
    "    return crop_data, df[columns].dropna().index\n",
    "\n",
    "# Standardize the data\n",
    "def standardize_data(data):\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(data)\n",
    "    return data_scaled\n",
    "\n",
    "# Perform spectral clustering with a fixed number of clusters\n",
    "def perform_spectral_clustering(data, n_clusters=5):\n",
    "    clustering = SpectralClustering(n_clusters=n_clusters, assign_labels=\"discretize\", random_state=0)\n",
    "    labels = clustering.fit_predict(data)\n",
    "    return labels\n",
    "\n",
    "# Iterate over each crop and perform clustering\n",
    "for crop in crops:\n",
    "    # Prepare the data for the crop\n",
    "    crop_data, indices = prepare_data_for_crop(df_agg_00_23, crop)\n",
    "    \n",
    "    # Standardize the data\n",
    "    crop_data_scaled = standardize_data(crop_data)\n",
    "    \n",
    "    # Perform spectral clustering with 5 clusters\n",
    "    labels = perform_spectral_clustering(crop_data_scaled, 5)\n",
    "    \n",
    "    # Add the cluster labels to the original dataframe\n",
    "    df_agg_00_23[f'{crop}_Spectral_Cluster_Custom'] = np.nan\n",
    "    df_agg_00_23.loc[indices, f'{crop}_Spectral_Cluster_Custom'] = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df_agg_00_23 is already loaded\n",
    "crops = ['Canola', 'Spring Wheat', 'Durum', 'Oats', 'Lentils', 'Peas', 'Barley']\n",
    "\n",
    "# Function to prepare data for each crop\n",
    "def prepare_data_for_crop(df, crop):\n",
    "    columns = [f'{crop}_mean', f'{crop}_std']\n",
    "    crop_data = df[columns].dropna().values\n",
    "    return crop_data, df[columns].dropna().index\n",
    "\n",
    "# Standardize the data\n",
    "def standardize_data(data):\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(data)\n",
    "    return data_scaled\n",
    "\n",
    "# Function to perform K-Means clustering\n",
    "def kmeans_clustering(data, n_clusters):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "    labels = kmeans.fit_predict(data)\n",
    "    return labels\n",
    "\n",
    "# Function to find the optimal number of clusters using the Elbow method\n",
    "def find_optimal_clusters(data, max_k):\n",
    "    distortions = []\n",
    "    for k in range(1, max_k+1):\n",
    "        kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "        kmeans.fit(data)\n",
    "        distortions.append(kmeans.inertia_)\n",
    "    optimal_k = distortions.index(min(distortions[1:])) + 1\n",
    "    return optimal_k, distortions\n",
    "\n",
    "# Iterate over each crop and perform clustering\n",
    "for crop in crops:\n",
    "    # Prepare the data for the crop\n",
    "    crop_data, indices = prepare_data_for_crop(df_agg_00_23, crop)\n",
    "    \n",
    "    # Standardize the data\n",
    "    crop_data_scaled = standardize_data(crop_data)\n",
    "    \n",
    "    # Find the optimal number of clusters using the Elbow method\n",
    "    optimal_k, distortions = find_optimal_clusters(crop_data_scaled, 10)\n",
    "    \n",
    "    # Perform K-Means clustering with the optimal number of clusters\n",
    "    optimal_labels = kmeans_clustering(crop_data_scaled, optimal_k)\n",
    "    \n",
    "    # Perform K-Means clustering with 5 clusters\n",
    "    fixed_labels = kmeans_clustering(crop_data_scaled, 5)\n",
    "    \n",
    "    # Add the cluster labels to the original dataframe\n",
    "    df_agg_00_23[f'{crop}_KMeans_Cluster_Optimal'] = np.nan\n",
    "    df_agg_00_23[f'{crop}_KMeans_Cluster_Custom'] = np.nan\n",
    "    df_agg_00_23.loc[indices, f'{crop}_KMeans_Cluster_Optimal'] = optimal_labels\n",
    "    df_agg_00_23.loc[indices, f'{crop}_KMeans_Cluster_Custom'] = fixed_labels\n",
    "    \n",
    "    # Plot the Elbow method graph\n",
    "    plt.plot(range(1, 11), distortions, marker='o')\n",
    "    plt.title(f'Elbow Method for {crop}')\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('Distortion')\n",
    "    plt.show()\n",
    "\n",
    "# Display the dataframe with the new cluster columns\n",
    "df_agg_00_23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# List of crops and corresponding cluster columns\n",
    "crops_clusters = {\n",
    "    'Canola': ['Canola_Spectral_Cluster_Optimal', 'Canola_Spectral_Cluster_Custom', 'Canola_KMeans_Cluster_Optimal', 'Canola_KMeans_Cluster_Custom'],\n",
    "    'Spring Wheat': ['Spring Wheat_Spectral_Cluster_Optimal', 'Spring Wheat_Spectral_Cluster_Custom', 'Spring Wheat_KMeans_Cluster_Optimal', 'Spring Wheat_KMeans_Cluster_Custom'],\n",
    "    'Durum': ['Durum_Spectral_Cluster_Optimal', 'Durum_Spectral_Cluster_Custom', 'Durum_KMeans_Cluster_Optimal', 'Durum_KMeans_Cluster_Custom'],\n",
    "    'Oats': ['Oats_Spectral_Cluster_Optimal', 'Oats_Spectral_Cluster_Custom', 'Oats_KMeans_Cluster_Optimal', 'Oats_KMeans_Cluster_Custom'],\n",
    "    'Lentils': ['Lentils_Spectral_Cluster_Optimal', 'Lentils_Spectral_Cluster_Custom', 'Lentils_KMeans_Cluster_Optimal', 'Lentils_KMeans_Cluster_Custom'],\n",
    "    'Peas': ['Peas_Spectral_Cluster_Optimal', 'Peas_Spectral_Cluster_Custom', 'Peas_KMeans_Cluster_Optimal', 'Peas_KMeans_Cluster_Custom'],\n",
    "    'Barley': ['Barley_Spectral_Cluster_Optimal', 'Barley_Spectral_Cluster_Custom', 'Barley_KMeans_Cluster_Optimal', 'Barley_KMeans_Cluster_Custom']\n",
    "}\n",
    "\n",
    "# Initialize a new DataFrame for ranked columns\n",
    "df_agg_00_23_ranked = df_agg_00_23.copy()\n",
    "\n",
    "# Rank the clusters based on the mean crop yield for each crop\n",
    "for crop, clusters in crops_clusters.items():\n",
    "    mean_column = f'{crop}_mean'\n",
    "    \n",
    "    for cluster_col in clusters:\n",
    "        # Calculate the mean crop yield grouped by the cluster column\n",
    "        cluster_means = df_agg_00_23.groupby(cluster_col).mean()[mean_column]\n",
    "        \n",
    "        # Rank the clusters based on the mean crop yield\n",
    "        df_agg_00_23_ranked[f'{cluster_col}_ranked'] = df_agg_00_23[cluster_col].map(cluster_means.rank(method='min'))\n",
    "\n",
    "# Drop old unranked cluster columns\n",
    "for clusters in crops_clusters.values():\n",
    "    df_agg_00_23_ranked.drop(columns=clusters, inplace=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
